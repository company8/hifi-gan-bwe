{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HIFIGAN+ BWE COLAB FORK\n",
        "\n",
        "Added features:\n",
        "* phase accurate chunking\n",
        "* batch processing\n",
        "* crafted for audio input with a cutoff between 12khz and 20khz\n",
        "* multiband ensembling with original file, keeping only \"what's needed\"\n",
        "* smooth lowpass filter applied to extra high frequency (more realistic output)\n",
        "\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "*Original work : https://github.com/brentspell/hifi-gan-bwe*\n",
        "\n",
        "*Tweaks by jarredou*"
      ],
      "metadata": {
        "id": "t4DX6cuNkGeV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLWbLtg_Zt3L"
      },
      "outputs": [],
      "source": [
        "# @title Installation { display-mode: \"form\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone -b fix_stream https://github.com/jarredou/hifi-gan-bwe\n",
        "#!pip install -r hifi-gan-bwe/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fySwTGxOYwl1"
      },
      "outputs": [],
      "source": [
        "# @title Inference { display-mode: \"form\" }\n",
        "%cd /content/hifi-gan-bwe\n",
        "\n",
        "import librosa\n",
        "import google.colab.files\n",
        "import numpy as np\n",
        "import torch\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio\n",
        "from hifi_gan_bwe import BandwidthExtender\n",
        "\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from scipy import signal\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def match_array_shapes(array_1:np.ndarray, array_2:np.ndarray):\n",
        "    if array_1.shape[1] > array_2.shape[1]:\n",
        "        array_1 = array_1[:,:array_2.shape[1]]\n",
        "    elif array_1.shape[1] < array_2.shape[1]:\n",
        "        padding = array_2.shape[1] - array_1.shape[1]\n",
        "        array_1 = np.pad(array_1, ((0,0), (0,padding)), 'constant', constant_values=0)\n",
        "    return array_1\n",
        "\n",
        "def lr_filter(audio, cutoff, filter_type, order=20, sr=48000):\n",
        "    audio = audio.T\n",
        "    nyquist = 0.5 * sr\n",
        "    normal_cutoff = cutoff / nyquist\n",
        "    b, a = signal.butter(order//2, normal_cutoff, btype=filter_type, analog=False)\n",
        "    sos = signal.tf2sos(b, a)\n",
        "    filtered_audio = signal.sosfiltfilt(sos, audio)\n",
        "    return filtered_audio.T\n",
        "\n",
        "def process_file(input_path,output_path):\n",
        "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
        "    filename =  Path(input_path).stem\n",
        "    print(f\"Processing {input_path}\")\n",
        "\n",
        "    input, sr = librosa.load(input_path, sr=None, mono=False)\n",
        "    #print(f\"input.shape={input.shape}\")\n",
        "\n",
        "    # resample to 24khz pre-processing\n",
        "    input_rs = librosa.resample(input,orig_sr=sr,target_sr=sr_ft, res_type='soxr_hq')\n",
        "    #sf.write(\"input2.wav\", input_rs.T, sr_ft)\n",
        "    # print(f\"input resampled.shape={input_rs.shape}\")\n",
        "\n",
        "    # chunking parameters\n",
        "    hop_length = chunk_size * sr_ft\n",
        "    # print(f\"hop_length={hop_length}\")\n",
        "\n",
        "    # process audio in chunks for each channel\n",
        "    output_chunks = []\n",
        "    num_chunks = input_rs.shape[1] // hop_length + 1\n",
        "    remaining_samples = input_rs.shape[1] % hop_length\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(num_chunks), unit='chunk'):\n",
        "            start = i * hop_length\n",
        "            end = start + hop_length\n",
        "            if end > input_rs.shape[1]:\n",
        "                end = input_rs.shape[1]\n",
        "            chunk = input_rs[:, start:end]\n",
        "\n",
        "            # Extend bandwidth using the model for each channel\n",
        "            chunk = np.stack([\n",
        "                model(torch.from_numpy(x).cuda(), sr_ft).cpu()\n",
        "                for x in chunk])\n",
        "\n",
        "            output_chunks.append(chunk)\n",
        "\n",
        "    # concatenate output chunks for each channel\n",
        "    output = np.concatenate(output_chunks, axis=1)\n",
        "    # print(f\"output.shape={output.shape}\")\n",
        "\n",
        "    # get low from origin input resampled\n",
        "    low = librosa.resample(input,orig_sr=sr,target_sr=48000, res_type='soxr_hq')\n",
        "    # print(f\"low.shape={low.shape}\")\n",
        "\n",
        "    # fix length issues\n",
        "    #low = match_array_shapes(low, output)\n",
        "    output = match_array_shapes(output, low)\n",
        "    # print(f\"low.shape={low.shape}\")\n",
        "\n",
        "    # linkwitz riley crossover\n",
        "    low = lr_filter(low.T, crossover_freq, 'lowpass')\n",
        "    high = lr_filter(output.T, crossover_freq, 'highpass')\n",
        "    # print(f\"high.shape={high.shape}\")\n",
        "\n",
        "    # sf.write(f\"{output_path}/low_upsampled.wav\", low, 48000, subtype='PCM_16')\n",
        "    # sf.write(f\"{output_path}/high_upsampled.wav\", high, 48000, subtype='PCM_16')\n",
        "\n",
        "\n",
        "    # add smoothing filter to high frequencies (more realistic)\n",
        "    high = lr_filter(high, 18000, 'lowpass', order=2)\n",
        "\n",
        "    # multiband ensemble\n",
        "    output = low + high\n",
        "    # print(f\"output.shape={output.shape}\")\n",
        "\n",
        "    # Resample output to the original sample rate\n",
        "    #output = librosa.resample(output, orig_sr=48000, target_sr=44100, res_type='soxr_hq')\n",
        "    #print(f\"output resampled.shape={output.shape}\")\n",
        "    sf.write(f\"{output_path}/{filename}_upsampled.wav\", output, 48000, subtype='PCM_16')\n",
        "    print(f\"Processing done !\\nFile exported to : {output_path}/{filename}_upsampled.wav\")\n",
        "\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/audio.wav\" #@param {type:\"string\"}\n",
        "output_path = \"/content/drive/MyDrive/output\" #@param {type:\"string\"}\n",
        "\n",
        "# chunksize in seconds\n",
        "chunk_size = \"90\" #@param [120, 90, 60, 30, 10, 1]\n",
        "chunk_size = int(chunk_size)\n",
        "\n",
        "#hifi-gan-bwe-10-42890e3-vctk-48kHz\n",
        "model = BandwidthExtender.from_pretrained(\"hifi-gan-bwe-13-59f00ca-vctk-24kHz-48kHz\").cuda()\n",
        "\n",
        "input_cutoff = \"14000\" #@param [20000, 19000, 18000, 17000, 16000, 14000, 13000, 13000, 12000]\n",
        "input_cutoff = int(input_cutoff)\n",
        "\n",
        "crossover_freq = input_cutoff - 500\n",
        "sr_ft = 24000\n",
        "\n",
        "\n",
        "if Path(input_path).is_file():\n",
        "  process_file(input_path,output_path)\n",
        "else:\n",
        "  for file_path in sorted(glob.glob(input_path+\"/*.*\"))[:]:\n",
        "    process_file(file_path,output_path)\n",
        "model = model.cpu()\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "#gc.collect()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
